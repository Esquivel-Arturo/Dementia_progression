\section{Response and inital state functions}
The initial state and response functions will often be written by a user.
Each returns a matrix with one row of eta (which may have only one row),
and one column per state.
If the gradient argument is set, then the result should have an added
attribute `gradient' which is an array whose first two dimensions match
the result, and last contains the derivative of each element with respect
to each column of eta.

\subsection{Categorical}
Several of the functions will use a multivariate logistic approach.
A vector of probabilities $\pi$ of length $m$ is related to a
linear predictor matrix $\eta$ with $m-1$ columns by
\begin{equation*}
  \pi_{ij} =  e^{\eta_{ij}}/\sum_{k=1}^m e^{\eta_{ik}}
\end{equation*}
where wlog $\eta_{ik}=0$ and is not passed as part of the array.
The derivative is
\begin{align*}
  \frac{\partial \pi_{ij}}{\eta_{il}} &= 
       e^{\eta_{ij}}\left[\frac{I_{(j=l)}}{\sum_k e^{\eta_{ik}}} -
        \frac{e^{\eta_{il}}}{\left(\sum_k e^{\eta_{ik}}\right)^2} \right] \; l<m \\
       &= \left\{ \begin{array}{rl}
           \pi_{ij}(1-\pi_{ij}) & j=l \\
           -\pi_{ij}\pi_{ij} & j\ne l  \end{array} \right. \\
\end{align*} 

which is a standard multinomial variance.
This is encapsulated in an mlogit function that is used as a building
block for the response and initial state functions.  
Unlike the above it puts the extra column first rather than last.
The \code{dmat} array has the partial of $p_{ij}$ wrt $\eta_{il}$ in the
(i,j,l) element.

<<response>>=
mlogit <- function(eta, gradient=FALSE) {
    m <- ncol(eta)
    denom <- 1 + rowSums(exp(eta))
    pi    <- cbind(1, exp(eta))/denom
    
    if (gradient) {
        if (nrow(eta) ==1) {  # only one subject
            pi2 <- drop(pi)
            #temp <- diag(pi) - outer(pi, pi) # next line is a touch faster
            temp <- diag(pi2) -  rep(pi2, m+1) * rep(pi2, each= m+1)
            dmat <- temp[,-1,drop=FALSE]
            dim(dmat) <- c(1, dim(dmat))  # make it a "row" per subject
        }
        else {
            dmat <- array(0., dim=c(nrow(eta), m+1, m))
            dmat[,1,] <- -pi[,-1]/denom
            for (j in 1:m) { # for each column of eta
                dmat[,j+1,] <- -pi[,j+1]* pi[,-1]
                dmat[,j+1, j] <- pi[,j+1]*(1-pi[,j+1])
            }
        }
        attr(pi, "gradient") <- dmat
    }
    pi
}
@ 

Here is a simple initial state function.  It will always be called with
a single row.  Usually a single call for all subjects, rarely one call
per subject (it is rare for initial state to depend on per-subject
covariates.)
If there were 6 states and only 2 columns for $\eta$, for example,  then we
assume that states 4--6 have no members at the start.
<<response>>=
hmminit <- function(nstate, eta, gradient=FALSE) {
    if (is.vector(eta)) eta <- matrix(eta, nrow=1)
    extra <- nstate - (1 + ncol(eta))
    if (extra < 0) 
        stop("too many linear predictors for the number of states")
    temp <- mlogit(eta, gradient)

    if (extra ==0) temp[1,]
    else {
        if (gradient) {
            d2 <- matrix(0, nstate, ncol(eta))
            dmat <- attr(temp, "gradient")[1,,]
            d2[1:nrow(dmat),] <- dmat

            p <- c(as.vector(temp), rep(0., extra))
            attr(p, "gradient") <- d2
            p
        }
        else c(temp, rep(0., extra))
    }
}    
@ 

Now use the mlogit tool to build a multinomial response function.
There user routine has two parameters which are a mapping vector and
an error matrix.
The mapping vector goes from the numeric state space to the states
for a particular attribute.
For instance we might have amyloid status and clinical stage
both contributing to the state, but this error matrix is only for clinical
stage.  Then the A-/MCI and A+/MCI are mapped to the same value by the
statemap vector.
For clinical status we might have the following error matrix:
\begin{center}
  \begin{tabular}{rccc}
    & CN & MCI & Dementia \\ \hline 
    CN &r& e1 & 0 \\
    MCI & e2 &r& e3 \\
    Dementia& 0 & e4 &r \\
  \end{tabular}
\end{center}
where the left margin are true states, vertical rows are observed states,
$e_i$ are four error probabilities and $r$ is the reference cell.
This matrix assumes that dementia is never mistaken as CN or vice versa.
The statemap vector shows how each true state maps to the clinical
status dimension, e.g., true state A-/N+/MCI maps to 2.

The hmmesetup routine allows the user to specify the matrix in terms of
the error values and the reference cell as -1.
It produces a contrast array and index list.
The index list says which linear predictors are used by true state 1, which
by true state 2, etc.  
<<response>>=
hmmesetup <- function(emat) {
    if (any(is.na(emat)) || any(emat != floor(emat)) || any(emat < -1))
        stop("emat must be an array of integers")
    if (all(emat <1)) stop("no linear predictors are specified")
    temp <- table(row(emat), factor(emat, c(-1, 1:max(emat))),
                  useNA="no")
    if (any(temp[,1] != 1))
        stop("each row of emat must have exactly one reference state")
    if (any(colSums(temp)==0)) stop("there are unused linear predictors")
    index <- tapply(emat, row(emat), function(x) x[x>0])
    
    new  <- matrix(0L, nrow=nrow(emat), ncol=ncol(emat))
    for (i in 1:nrow(emat)) {
        used <- match(emat[i,], index[[i]], nomatch=0)
        new[i, emat[i,]==-1] <- 1  # the reference cell
        new[i, used>0] <- 1 + used[used>0]
    }
    result <- list(index = index, emat= new)
    class(result) <- "hmmesetup"
    result
}
@ 

It is legal to use a particular linear predictor multiple times in a
single row (equal error rates), or use the same one in multiple rows.
The above setup matrix has ensures that the right sums occur.

<<response>>=
hmmemat <- function(y, nstate, eta, gradient=FALSE, statemap, setup) {
    if (!is.matrix(eta)) eta <- matrix(eta, nrow=length(y))
    if (!inherits(setup, "hmmesetup")) 
        stop("setup must be the result of hmmesetup")
    if (length(statemap) != nstate) stop("wrong length for statemap")
    if (any(statemap <1 | statemap > nrow(setup$emat)))
        stop("statemap does not match setup")
    if (any(y<1 | y > ncol(setup$emat))) stop("y does not match setup")
    
    ny <- length(y)
    rmat <- matrix(0., nrow=nstate, ncol=ny)
    if (gradient) gmat <- array(0., dim=c(nstate, ny, ncol(eta)))
    for (i in 1:length(setup$index)) {
        sindx <- which(statemap ==i)
        if (length(setup$index[[i]]) ==0) {
            # no errors for this state, e.g., death
            indx2 <- which(setup$emat[i,] ==1) # there should be only 1
            rmat[sindx, y %in% indx2] <- 1
            # gradient is zero for these cells
        }
        else {
            mtemp <- mlogit(eta[, setup$index[[i]], drop=FALSE], gradient)
            indx2 <- setup$emat[i,]
            # say that indx2 = 0 2 1 0.  
            #  mtemp will have one row per subject, rmat one col per subject  
            #  rmat[, y==1] is left alone, also rmat[,y==4]; these outcomes
            #      by definition can't happen, so rmat stays at 0
            #  rmat[i, y==2] = mtemp[y==2, indx2[2]] for each i in sindx
            #  rmat[i, y==3] = mtemp[y==3, indx2[3]] for each i in sindx
            #
            #  indx2[y] is the column of mtemp to grab for each y, but mind
            #    the zeros, rows go from 1 to ny
            #  As we march down mtemp from 1 to ny (across rmat) the element
            #    we want is "none" if indx2[y]==0, and 1:ny + ny*(indx2[y]-1)
            #    for the others = standard R indexing.
            #  The last bit of trickery is that rmat will have repeated rows
            #    for elements of sindx, and since the first index varies
            #    fastest we can simply "stutter" the index.
            indx2 <- indx2[y]
            indx3 <- ifelse(indx2==0, 0, 1:ny + ny*(indx2-1)) # matrix index
            indx3 <- rep(indx3, each=length(sindx))  # stutter
            rmat[sindx, indx2>0] <- mtemp[indx3]
            if (gradient) {
                indx4 <- setup$index[[i]]
                for (k in 1:length(indx4)) 
                    gmat[sindx, indx2 >0, indx4[k]] <-
                         (attr(mtemp, "gradient")[,,k])[indx3]
            }
        }
    }
    if (gradient) attr(rmat, "gradient") <- gmat
    rmat
    }
@ 

This second routine does not use an error matrix.  It was my first cut, and
is not as intuitive to use.
Here statemap contains both quantities.

<<response>>=
# a multinomial response function
hmulti <- function(y, nstate, eta, gradient=FALSE, statemap) {
    if (!is.matrix(eta)) eta <- matrix(eta, nrow=length(y))
    temp <- mlogit(eta, gradient)
    if (nrow(temp) != length(y)) 
        stop("nrow(eta) != length(y)")
    stopifnot(is.matrix(statemap), nrow(statemap)== nstate,
              ncol(statemap)== (ncol(eta) +1))
    if (gradient) {
        gmat <- array(0., dim=c(nstate, length(y), ncol(eta)))
        gtemp <- attr(temp, "gradient")
    }
    rmat <- matrix(0., nrow= nstate, ncol =length(y))
        
    # This function is called once per subject: both y and nstate are short
    #  A loop is simpler than fancy indexing
    # (It looks like you could do it all at once, but gtemp[vector, vector, ]
    #  will grab too much.)
    for (i in 1:nstate) {
        indx1 <- match(y, statemap[i,], nomatch=0)
        for (obs in which(indx1>0)) {
            rmat[i, obs] <- temp[obs, indx1[obs]]
            if (gradient) gmat[i,obs,] <- gtemp[obs, indx1[obs],]
        }
    }
    if (gradient) attr(rmat, "gradient") <- gmat
    rmat
}
@ 

\subsection{Continuous}
Consider PIB as a continuous response with cutpoints at 1.3 and 1.5 for 
categories of low, medium and high for the true states.
Call these A0, A1 and A2.  
As a very simple model assume that the numeric response is the convolution
of a uniform over the state along with a Gaussian error $N(0, \tau^2)$.
If the subject's true state is 1.3--1.5 then the true amlyoid measurement is
uniform over 1.3--1.5.  
Then the density for an observed response from category 2 is
\begin{align*}
  g(z) &= \frac{1}{\tau \sqrt{2\pi}} \int_{1.3}^{1.5} e^{-(x-z)^2 /2\tau^2} dx \\
       &= \Phi([1.5-z]/\tau) - \Phi([1.3 -z]/\tau)
\end{align*}
This is a very simple to evaluate since 
$\Phi(a/s)$ = \code{pnorm(a, 0, s)}.
Technically I should also normalize
by the length of the interval, i.e.,
use a density of 1/(1.5-1.3) rather than 1 for the uniform distribution,
but has neglibile effect on the loglikelihood.

The derivative is a bit harder. By dominated convergence we can pass the
derivative inside the integral; the derivative of the interior portion
is 
\begin{equation*}
  \frac{\partial\,  e^{-(x-z)^2 /2\tau^2}}{\partial \tau} =
       e^{-(x-z)^2 /2\tau^2} (x-z)^2 /\tau^3
\end{equation*}
which we now need to integrate.

I first did this by hand using a standard table of integrals, and then
discovered sympi.org, which can do it all.  The value of the integral
is simply 
\begin{equation*}
  \phi(x-z, \tau) (x-z)/\tau \,,
\end{equation*}
a scaled Gaussian density.
The in-between steps are mess; it is a major surprise that it all
cancels out so nicely.

The Gaussian has very short tails, which could be an impediment if there
are any outliers in the $y$ values.  An alternative is the
logisitic distribution, which has density
\begin{equation*}
  l(x) = \frac{e^{x/\tau}}{\tau(1+ e^{x/\tau})^2}
\end{equation*}
Use the same steps of differentiaion with respect to $\tau$ and then
integration with respect to $x$, and let $l$ and $L$ be the density and CDF
of the distribution.  The derivatives and integrals below are done using
live.sympy.org.
\begin{align*}
  g(z) &= \frac{1}{s} \int_{1.3}^{1.5} \frac{e^{(x-z)/\tau}}{\tau(1+ e^{(x-z)/\tau})^2} dx \\
       &= L(1.5-z, \tau) - L(1.3 -z, \tau)
  \frac{\partial g(z)}{\tau} &= 
     \int_{1.3}^{1.5} \frac{\partial \frac{e^{(x-z)/\tau}}{\tau(1+ e^{(x-z)/\tau})^2}}
        {\partial \tau} dx \\
     &= \int_{1.3}^{1.5}
       l(x-z, \tau)\left( \frac{2(x-z)e^{(x-z)/\tau}}{\tau^2 (1+ e^{(x-z)/\tau})}
         - \frac{1+ x-z}{\tau^2} \right) \,dx
     &= \left(- l(x-z, \tau) \frac{x-z}{\tau} \right)_{1.3}^{1.5} \\
\end{align*}
This is again just a scaled density!  

In the function below \code{cuts} should be a matrix with one row
per state and two columns giving the lower and upper cutpoints for that
state.  This is expanded using the statemap vector.
In our standard model of A-N-, A+N-, A-N+, A+N+, death consider
the call for the amyloid state.  The cuts matrix will be 2 by 2.
The statemap vector is c(1,2,1,2,0) which maps the 6 model states to the
2 amlyoid states.  The 0 says that death is neither A- or A+ and leads to
zero probability for a non-missing amlyoid and death.

The dnorm and pnorm functions do fine with infinite arguments
but the product x*dnorm(x) does not.  We know (but the computer doesn't)
that the product goes to zero.
Also, the parameter will be $\tau = \exp(\eta)$ so as to avoid zero, and
\begin{align*}
  \frac{\partial g}{\partial \eta} &= \frac{\partial g}{\partial \tau}
    \partial{\tau}{\partial \eta} \\
     &= \frac{\partial g}{\partial \tau} \tau
\end{align*}
which cancels out the $\tau$ term in the denominator.

<<response>>=
hmmncut <- function(y, nstate, eta, gradient=FALSE, cuts, statemap) {
    xd <- function(x, sd)  # x * dnorm(x)
        ifelse(is.finite(x), x * dnorm(x, 0, sd), 0)
        
    # This only accepts a single parameter
    if (is.matrix(eta) && ncol(eta) != 1) 
        stop("only a single linear predictor is allowed")
    estd <- exp(as.vector(eta))
    if (length(statemap) != nstate) stop("wrong length for statemap")
    if (!is.matrix(cuts) || ncol(cuts) !=2) 
        stop("cuts must be a 2 column matrix")
    if (any(statemap!= floor(statemap) | statemap <0))
        stop ("statemap must be integers >=0")
    if (any(statemap > nrow(cuts)))
        stop("statemap and cuts do not agree")
    yprob <- matrix(0., nstate, length(y))
    if (gradient) ygrad <- array(0., dim=c(nstate, length(y), 1))

    for (i in which(statemap>0)) {
        j <- statemap[i]
        yprob[i,] <- pnorm(cuts[j,2] -y, 0, estd) - pnorm(cuts[j,1] -y, 0, estd)
        if (gradient) 
            ygrad[i,,1] <- xd(cuts[j,1]-y, estd) - xd(cuts[j,2]-y, estd)
    }

    if (gradient) attr(yprob, "gradient") <- ygrad
    yprob
}
        
hmmlcut <- function(y, nstate, eta, gradient=FALSE, cuts, statemap) {
    # The canonical form of the distribution has variance pi^2/3
    #  We want eta=0 to be a variance of 1, so the variance parameter
    #  is rescaled.  
    
    xd <- function(x, sd)  # x * dnorm(x)
        ifelse(is.finite(x), x * dlogis(x, 0, sd), 0)
        
    # This only accepts a single parameter
    if (is.matrix(eta) && ncol(eta) != 1) 
        stop("only a single linear predictor is allowed")
    estd <- exp(as.vector(eta))* sqrt(3)/pi
    if (length(statemap) != nstate) stop("wrong length for statemap")
    if (!is.matrix(cuts) || ncol(cuts) !=2) 
        stop("cuts must be a 2 column matrix")
    if (any(statemap!= floor(statemap) | statemap <0))
        stop ("statemap must be integers >=0")
    if (any(statemap > nrow(cuts)))
        stop("statemap and cuts do not agree")
    yprob <- matrix(0., nstate, length(y))
    if (gradient) ygrad <- array(0., dim=c(nstate, length(y), 1))

    for (i in which(statemap >0)) {
        j <- statemap[i]
        yprob[i,] <- plogis(cuts[j,2] -y, 0, estd) - 
                     plogis(cuts[j,1] -y, 0, estd)
        if (gradient) 
            ygrad[i,,1] <- xd(cuts[j,1]-y, estd) - xd(cuts[j,2]-y, estd)
    }

    if (gradient) attr(yprob, "gradient") <- ygrad
    yprob
}
@ 
